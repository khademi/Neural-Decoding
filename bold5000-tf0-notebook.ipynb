{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77466e95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:09.301239Z",
     "iopub.status.busy": "2022-08-25T02:56:09.300830Z",
     "iopub.status.idle": "2022-08-25T02:56:36.879995Z",
     "shell.execute_reply": "2022-08-25T02:56:36.879260Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/pbs.4029679.pbsha.ib.sockeye/matplotlib-_hdi47zv because the default path (/home/mkhademi/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n"
     ]
    }
   ],
   "source": [
    "import nilearn\n",
    "from nilearn import image\n",
    "import tensorflow as tf\n",
    "#from keras.applications.nasnet import preprocess_input\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "#from keras.applications.nasnet import decode_predictions\n",
    "#from keras.preprocessing.image import load_img\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import json, pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.image import mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb9e4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:36.884159Z",
     "iopub.status.busy": "2022-08-25T02:56:36.883587Z",
     "iopub.status.idle": "2022-08-25T02:56:49.030343Z",
     "shell.execute_reply": "2022-08-25T02:56:49.029625Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/arc/project/st-ipor-1/mkhademi/BOLD5000_2.0/'\n",
    "output_dir = '/scratch/st-ipor-1/mkhademi/'\n",
    "# roi_dir = data_dir + 'BOLD5000_GLMsingle_ROI_betas/py/'\n",
    "roi_dir = output_dir + 'image_data/parcels/'\n",
    "warp_dir = '/scratch/st-ipor-1/mkhademi/image_data/MRICroGL_extractedBrain/'\n",
    "with open(data_dir + 'image_data/MSCOCO/annotations/' + 'instances_train2014.json') as json_data:\n",
    "    coco_anns = json.load(json_data)\n",
    "    json_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c97c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:49.034351Z",
     "iopub.status.busy": "2022-08-25T02:56:49.033636Z",
     "iopub.status.idle": "2022-08-25T02:56:49.875513Z",
     "shell.execute_reply": "2022-08-25T02:56:49.874823Z"
    }
   },
   "outputs": [],
   "source": [
    "imagenet_anns = pd.read_csv(data_dir + 'image_data/LOC_train_solution.csv', sep = ',')\n",
    "f = open(data_dir + 'image_data/LOC_synset_mapping.txt', 'r')\n",
    "imagenet_categories = []\n",
    "for x in f:\n",
    "    imagenet_categories.append(x.split()[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce647bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:49.879242Z",
     "iopub.status.busy": "2022-08-25T02:56:49.878872Z",
     "iopub.status.idle": "2022-08-25T02:56:49.888934Z",
     "shell.execute_reply": "2022-08-25T02:56:49.888241Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_dir + 'image_data/extra_annotations.pickle', 'rb') as f:\n",
    "    extra_annotations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8547010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:49.892663Z",
     "iopub.status.busy": "2022-08-25T02:56:49.892325Z",
     "iopub.status.idle": "2022-08-25T02:56:49.906648Z",
     "shell.execute_reply": "2022-08-25T02:56:49.906047Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_convert = {0: [], 1: [444], 2: [705, 751, 817, 829], 3: [], 4: [403], 5: [779, 654], 6: [], 7: [555, 569, 717, 864], \n",
    "               8: [449, 554, 625, 833, 814], 9: [920], 10: [], 11: [919], 12: [], 13: [704], 14: [703], \n",
    "               15: [134] + [i for i in range(7, 25)], 16: [i for i in range(281, 286)], 17: [i for i in range(151, 269)], \n",
    "               18: [], 19: [349], 20: [], 21: [385, 386], 22: [388], 23: [340], 24: [], 25: [515], 26: [414], 27: [879], \n",
    "               28: [770], 29: [], 30: [], 31: [457], 32: [], 33: [], 34: [795], 35: [], 36: [805, 852, 522, 574, 722, 768],\n",
    "               37: [], 38: [], 39: [], 40: [], 41: [], 42: [], 43: [898, 907, 440], 44: [923], 45: [], 46: [968], 47: [],\n",
    "               48: [623], 49: [910], 50: [659, 809], 51: [954], 52: [], 53: [], 54: [950], 55: [937], 56: [], 57: [934],\n",
    "               58: [963], 59: [], 60: [], 61: [423, 559, 765], 62: [831], 63: [], 64: [], 65: [], 66: [532], 67: [904],\n",
    "               68: [526], 69: [861], 70: [799], 71: [851], 72: [620], 73: [673], 74: [761], 75: [878], 76: [487], 77: [651],\n",
    "               78: [], 79: [859], 80: [], 81: [760], 82: [], 83: [917], 84: [409, 530, 892], 85: [883], 86: [], 87: [850],\n",
    "               88: [589], 89: [], 90: []}\n",
    "cat_conv_rev = {}\n",
    "for key, val in cat_convert.items():\n",
    "    for x in val:\n",
    "        cat_conv_rev[x] = key\n",
    "super_cat = {0: [0], 1: [i for i in range(1, 9)], 2: [i for i in range(9, 15)], 3: [i for i in range(15, 25)],\n",
    "             4: [i for i in range(25, 33)], 5: [i for i in range(33, 43)], 6: [i for i in range(43, 51)],\n",
    "             7: [i for i in range(51, 61)], 8: [i for i in range(61, 71)], 9: [i for i in range(71, 77)],\n",
    "             10: [i for i in range(77, 83)], 11: [i for i in range(83, 91)]}\n",
    "tool = [27, 30, 38, 39, 42, 47, 48, 49, 73, 74, 76, 86, 88, 89] \n",
    "super_cat_rev = {}\n",
    "for key, val in super_cat.items():\n",
    "    for x in val:\n",
    "        super_cat_rev[x] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2359499b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:49.910490Z",
     "iopub.status.busy": "2022-08-25T02:56:49.909939Z",
     "iopub.status.idle": "2022-08-25T02:56:49.928511Z",
     "shell.execute_reply": "2022-08-25T02:56:49.927834Z"
    }
   },
   "outputs": [],
   "source": [
    "subjs = ['CSI1', 'CSI2', 'CSI3', 'CSI4']\n",
    "sub = subjs[0]  \n",
    "if sub == 'CSI4':\n",
    "    seses = ['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'ses-06', 'ses-07', 'ses-08',\n",
    "             'ses-09'] \n",
    "else:\n",
    "    seses = ['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'ses-06', 'ses-07', 'ses-08', \n",
    "             'ses-09', 'ses-10', 'ses-11', 'ses-12', 'ses-13', 'ses-14', 'ses-15']\n",
    "'''\n",
    "if sub == subjs[0]:\n",
    "    roi_names = ['LHEarlyVis','LHLOC','LHOPA','LHPPA','LHRSC','RHEarlyVis','RHLOC','RHOPA',\n",
    "                 'RHPPA','RHRSC']\n",
    "if sub == subjs[1]:\n",
    "    roi_names = ['LHEarlyVis','LHLO','LHOPA','LHPPA','LHRSC','RHEarlyVis','RHLO','RHOPA',\n",
    "                 'RHPPA','RHRRSC']\n",
    "if sub == subjs[2]:\n",
    "    roi_names = ['LHEarlyVis','LHLO','LHOPA','LHPPA','LHRSC','RHEarlyVis','RHLO','RHOPA',\n",
    "                 'RHPPA','RHRSC']\n",
    "if sub == subjs[3]:\n",
    "    roi_names = ['LHEarlyVis','LHLOC','LHOPA','LHPPA','LHRSC','RHEarlyVis','RHLOC','RHOPA',\n",
    "                 'RHPPA','RHRSC']\n",
    "'''\n",
    "roi_names=['lFFA','rFFA','lOFA','rOFA','lSTS','rSTS','lLOC','rLOC','lPPA','rPPA','lRSC','rRSC','lTOS','rTOS','lEBA','rEBA']\n",
    "imgnames = []\n",
    "f = open(data_dir + sub + '_imgnames.txt', 'r')\n",
    "for imgname in f:\n",
    "    imgnames.append(imgname[:-1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ce5b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T02:56:49.932641Z",
     "iopub.status.busy": "2022-08-25T02:56:49.932289Z",
     "iopub.status.idle": "2022-08-25T03:10:55.903261Z",
     "shell.execute_reply": "2022-08-25T03:10:55.902105Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dict = {}\n",
    "img_dict_super = {}\n",
    "coco_category_count = {}\n",
    "coco_super_count = {}\n",
    "coco_category_count_trials = {}\n",
    "coco_super_count_trials = {}\n",
    "imagenet_category_count = {}\n",
    "imagenet_super_count = {}\n",
    "imagenet_category_count_trials = {}\n",
    "imagenet_super_count_trials = {}\n",
    "f_coco = open(output_dir + 'image_data/coco_cat.txt', 'w')\n",
    "f_imagenet = open(output_dir + 'image_data/imagenet_cat.txt', 'w')\n",
    "coco_total = 0\n",
    "imagenet_total = 0\n",
    "coco_total_trials = 0\n",
    "imagenet_total_trials = 0\n",
    "\n",
    "for imgname in imgnames:\n",
    "    if imgname[0]  == 'C': \n",
    "        # os.system('cp ' + data_dir + 'image_data/MSCOCO/images/train2014/' + imgname + ' ' + data_dir + 'image_data/drop_box_coco/')\n",
    "        img_id = int(imgname[15:27]) \n",
    "        \n",
    "        tmp_set = set()\n",
    "        super_tmp_set = set() \n",
    "        coco_total_trials += 1 \n",
    "        if extra_annotations[imgname] == 'face':\n",
    "            if 's_0' in coco_super_count_trials:\n",
    "                coco_super_count_trials['s_0'] += 1\n",
    "            else:\n",
    "                coco_super_count_trials['s_0'] = 1\n",
    "        for i in range(len(coco_anns['annotations'])):\n",
    "            if coco_anns['annotations'][i]['image_id'] == img_id:\n",
    "                category_id = coco_anns['annotations'][i]['category_id'] - 1\n",
    "                super_id = super_cat_rev[category_id]\n",
    "                if not 'c_' + str(category_id) in tmp_set:\n",
    "                    if 'c_' + str(category_id) in coco_category_count_trials:\n",
    "                        coco_category_count_trials['c_' + str(category_id)] += 1\n",
    "                    else:\n",
    "                        coco_category_count_trials['c_' + str(category_id)] = 1\n",
    "                    tmp_set.add('c_' + str(category_id))\n",
    "                if super_id > 0:    \n",
    "                    if not 's_' + str(super_id) in super_tmp_set:\n",
    "                        if 's_' + str(super_id) in coco_super_count_trials:\n",
    "                            coco_super_count_trials['s_' + str(super_id)] += 1\n",
    "                        else:\n",
    "                            coco_super_count_trials['s_' + str(super_id)] = 1\n",
    "                        super_tmp_set.add('s_' + str(super_id)) \n",
    "                    \n",
    "        tmp_set = set()\n",
    "        super_tmp_set = set()\n",
    "        if not imgname in img_dict:\n",
    "            f_coco.write(imgname +': ')  \n",
    "            img_dict[imgname] = np.zeros(90, dtype=np.int32)\n",
    "            img_dict_super[imgname] = np.zeros(12, dtype=np.int32)\n",
    "            coco_total += 1 \n",
    "            if extra_annotations[imgname] == 'face':\n",
    "                img_dict_super[imgname][0] = 1\n",
    "                if 's_0' in coco_super_count:\n",
    "                    coco_super_count['s_0'] += 1\n",
    "                else:\n",
    "                    coco_super_count['s_0'] = 1 \n",
    "            for i in range(len(coco_anns['annotations'])):\n",
    "                if coco_anns['annotations'][i]['image_id'] == img_id:\n",
    "                    category_id = coco_anns['annotations'][i]['category_id'] - 1\n",
    "                    img_dict[imgname][category_id] = 1\n",
    "                    super_id = super_cat_rev[category_id]\n",
    "                    if not 'c_' + str(category_id) in tmp_set:\n",
    "                        if 'c_' + str(category_id) in coco_category_count:\n",
    "                            coco_category_count['c_' + str(category_id)] += 1\n",
    "                        else:\n",
    "                            coco_category_count['c_' + str(category_id)] = 1\n",
    "                        tmp_set.add('c_' + str(category_id))\n",
    "                    if super_id > 0:   \n",
    "                        if not 's_' + str(super_id) in super_tmp_set:\n",
    "                            img_dict_super[imgname][super_id] = 1 \n",
    "                            if 's_' + str(super_id) in coco_super_count:\n",
    "                                coco_super_count['s_' + str(super_id)] += 1\n",
    "                            else:\n",
    "                                coco_super_count['s_' + str(super_id)] = 1\n",
    "                            super_tmp_set.add('s_' + str(super_id))    \n",
    "                    #if category_id == 0:\n",
    "                    # # # os.system('cp ' + data_dir + 'image_data/MSCOCO/images/train2014/' + imgname + ' ' + data_dir + 'image_data/person_coco/')\n",
    "                    f_coco.write('c_' + str(category_id) + ' ')\n",
    "            f_coco.write('\\n')\n",
    "    if imgname[0]  == 'n' and (imgname[1] == '0' or imgname[1] == '1'):\n",
    "        # os.system('cp ' + data_dir + 'image_data/ILSVRC/Data/CLS-LOC/train/' + imgname[0:9] + '/' + imgname + ' ' + data_dir + 'image_data/drop_box_imagenet/')\n",
    "        category_id = imagenet_categories.index(imgname[:9])\n",
    "        flag = False\n",
    "        if extra_annotations[imgname] == 'person_noface' or extra_annotations[imgname] == 'face':\n",
    "            imagenet_total_trials += 1\n",
    "            flag = True\n",
    "            if 'c_0' in imagenet_category_count_trials:\n",
    "                imagenet_category_count_trials['c_0'] += 1\n",
    "            else:\n",
    "                imagenet_category_count_trials['c_0'] = 1\n",
    "        if extra_annotations[imgname] == 'face':\n",
    "            if 's_0' in imagenet_super_count_trials:\n",
    "                imagenet_super_count_trials['s_0'] += 1\n",
    "            else:\n",
    "                imagenet_super_count_trials['s_0'] = 1\n",
    "        \n",
    "        if category_id in cat_conv_rev:\n",
    "            if not flag:\n",
    "                imagenet_total_trials += 1\n",
    "            \n",
    "            super_id = super_cat_rev[cat_conv_rev[category_id]]\n",
    "            if 'c_' + str(cat_conv_rev[category_id]) in imagenet_category_count_trials:\n",
    "                imagenet_category_count_trials['c_' + str(cat_conv_rev[category_id])] += 1\n",
    "            else:\n",
    "                imagenet_category_count_trials['c_' + str(cat_conv_rev[category_id])] = 1\n",
    "\n",
    "            if 's_' + str(super_id) in imagenet_super_count_trials:\n",
    "                imagenet_super_count_trials['s_' + str(super_id)] += 1\n",
    "            else:\n",
    "                imagenet_super_count_trials['s_' + str(super_id)] = 1\n",
    "        \n",
    "        if not imgname in img_dict:\n",
    "            img_dict_super[imgname] = np.zeros(12, dtype=np.int32)\n",
    "            flag = False\n",
    "            if extra_annotations[imgname] == 'person_noface' or extra_annotations[imgname] == 'face':\n",
    "                imagenet_total += 1\n",
    "                flag = True\n",
    "                if 'c_0' in imagenet_category_count:\n",
    "                    imagenet_category_count['c_0'] += 1\n",
    "                else:\n",
    "                    imagenet_category_count['c_0'] = 1\n",
    "            if extra_annotations[imgname] == 'face':\n",
    "                img_dict_super[imgname][0] = 1\n",
    "                if 's_0' in imagenet_super_count:\n",
    "                    imagenet_super_count['s_0'] += 1\n",
    "                else:\n",
    "                    imagenet_super_count['s_0'] = 1\n",
    "\n",
    "            f_imagenet.write(imgname +': ')\n",
    "            f_imagenet.write('c_' + str(category_id) + ' ')\n",
    "            f_imagenet.write('\\n')\n",
    "            if category_id in cat_conv_rev:\n",
    "                if not flag:\n",
    "                    imagenet_total += 1\n",
    "                if 'c_' + str(cat_conv_rev[category_id]) in imagenet_category_count:\n",
    "                    imagenet_category_count['c_' + str(cat_conv_rev[category_id])] += 1\n",
    "                else:\n",
    "                    imagenet_category_count['c_' + str(cat_conv_rev[category_id])] = 1\n",
    "                    \n",
    "                super_id = super_cat_rev[cat_conv_rev[category_id]] \n",
    "                img_dict_super[imgname][super_id] = 1\n",
    "                if 's_' + str(super_id) in imagenet_super_count:\n",
    "                    imagenet_super_count['s_' + str(super_id)] += 1\n",
    "                else:\n",
    "                    imagenet_super_count['s_' + str(super_id)] = 1\n",
    "                    \n",
    "            img_dict[imgname] = np.zeros(1000, dtype=np.int32)\n",
    "            img_dict[imgname][category_id] = 1\n",
    "\n",
    "f_coco.close()\n",
    "f_imagenet.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d92e40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.907345Z",
     "iopub.status.busy": "2022-08-25T03:10:55.906967Z",
     "iopub.status.idle": "2022-08-25T03:10:55.912780Z",
     "shell.execute_reply": "2022-08-25T03:10:55.912100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 297), (1, 2), (2, 8), (3, 0), (4, 2), (5, 4), (6, 0), (7, 8), (8, 10), (9, 2), (10, 0), (11, 2), (12, 0), (13, 2), (14, 2), (15, 38), (16, 10), (17, 236), (18, 0), (19, 2), (20, 0), (21, 4), (22, 2), (23, 2), (24, 0), (25, 2), (26, 2), (27, 2), (28, 2), (29, 0), (30, 0), (31, 2), (32, 0), (33, 0), (34, 2), (35, 0), (36, 12), (37, 0), (38, 0), (39, 0), (40, 0), (41, 0), (42, 0), (43, 6), (44, 2), (45, 0), (46, 2), (47, 0), (48, 2), (49, 2), (50, 4), (51, 2), (52, 0), (53, 0), (54, 2), (55, 2), (56, 0), (57, 2), (58, 2), (59, 0), (60, 0), (61, 6), (62, 2), (63, 0), (64, 0), (65, 0), (66, 2), (67, 2), (68, 2), (69, 2), (70, 2), (71, 2), (72, 2), (73, 2), (74, 2), (75, 2), (76, 2), (77, 2), (78, 0), (79, 2), (80, 0), (81, 2), (82, 0), (83, 2), (84, 6), (85, 2), (86, 0), (87, 2), (88, 2), (89, 0), (90, 0), "
     ]
    }
   ],
   "source": [
    "for i in range(91):\n",
    "    if 'c_'+ str(i) in imagenet_category_count:\n",
    "        print((i, imagenet_category_count['c_'+ str(i)]), end=', ')\n",
    "    else: \n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f77dca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.915818Z",
     "iopub.status.busy": "2022-08-25T03:10:55.915483Z",
     "iopub.status.idle": "2022-08-25T03:10:55.920511Z",
     "shell.execute_reply": "2022-08-25T03:10:55.919922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 324), (1, 5), (2, 11), (3, 0), (4, 2), (5, 4), (6, 0), (7, 11), (8, 10), (9, 2), (10, 0), (11, 2), (12, 0), (13, 2), (14, 2), (15, 38), (16, 10), (17, 242), (18, 0), (19, 2), (20, 0), (21, 4), (22, 2), (23, 2), (24, 0), (25, 2), (26, 2), (27, 2), (28, 2), (29, 0), (30, 0), (31, 2), (32, 0), (33, 0), (34, 2), (35, 0), (36, 12), (37, 0), (38, 0), (39, 0), (40, 0), (41, 0), (42, 0), (43, 9), (44, 2), (45, 0), (46, 2), (47, 0), (48, 2), (49, 2), (50, 4), (51, 2), (52, 0), (53, 0), (54, 2), (55, 2), (56, 0), (57, 2), (58, 2), (59, 0), (60, 0), (61, 6), (62, 2), (63, 0), (64, 0), (65, 0), (66, 5), (67, 2), (68, 2), (69, 2), (70, 2), (71, 2), (72, 2), (73, 2), (74, 2), (75, 2), (76, 2), (77, 2), (78, 0), (79, 2), (80, 0), (81, 2), (82, 0), (83, 2), (84, 6), (85, 5), (86, 0), (87, 2), (88, 2), (89, 0), (90, 0), "
     ]
    }
   ],
   "source": [
    "for i in range(91):\n",
    "    if 'c_'+ str(i) in imagenet_category_count_trials:\n",
    "        print((i, imagenet_category_count_trials['c_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059c6310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.923627Z",
     "iopub.status.busy": "2022-08-25T03:10:55.923325Z",
     "iopub.status.idle": "2022-08-25T03:10:55.927740Z",
     "shell.execute_reply": "2022-08-25T03:10:55.927118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 215), (1, 34), (2, 8), (3, 294), (4, 10), (5, 14), (6, 18), (7, 10), (8, 18), (9, 12), (10, 6), (11, 14), "
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    if 's_'+ str(i) in imagenet_super_count:\n",
    "        print((i, imagenet_super_count['s_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3ae1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.930757Z",
     "iopub.status.busy": "2022-08-25T03:10:55.930459Z",
     "iopub.status.idle": "2022-08-25T03:10:55.934890Z",
     "shell.execute_reply": "2022-08-25T03:10:55.934285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 233), (1, 43), (2, 8), (3, 300), (4, 10), (5, 14), (6, 21), (7, 10), (8, 21), (9, 12), (10, 6), (11, 17), "
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    if 's_'+ str(i) in imagenet_super_count_trials:\n",
    "        print((i, imagenet_super_count_trials['s_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519e49d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.938027Z",
     "iopub.status.busy": "2022-08-25T03:10:55.937607Z",
     "iopub.status.idle": "2022-08-25T03:10:55.942181Z",
     "shell.execute_reply": "2022-08-25T03:10:55.941595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 916), (1, 39), (2, 156), (3, 41), (4, 63), (5, 46), (6, 62), (7, 65), (8, 48), (9, 64), (10, 36), (11, 0), (12, 19), (13, 6), (14, 91), (15, 78), (16, 57), (17, 63), (18, 50), (19, 36), (20, 42), (21, 57), (22, 24), (23, 65), (24, 84), (25, 0), (26, 68), (27, 51), (28, 0), (29, 0), (30, 97), (31, 53), (32, 21), (33, 25), (34, 79), (35, 43), (36, 57), (37, 30), (38, 43), (39, 55), (40, 38), (41, 82), (42, 46), (43, 104), (44, 0), (45, 36), (46, 129), (47, 40), (48, 55), (49, 52), (50, 118), (51, 42), (52, 46), (53, 28), (54, 48), (55, 41), (56, 34), (57, 17), (58, 37), (59, 27), (60, 26), (61, 177), (62, 67), (63, 71), (64, 49), (65, 0), (66, 175), (67, 0), (68, 0), (69, 37), (70, 0), (71, 63), (72, 55), (73, 40), (74, 42), (75, 38), (76, 70), (77, 22), (78, 46), (79, 4), (80, 87), (81, 38), (82, 0), (83, 87), (84, 94), (85, 64), (86, 13), (87, 22), (88, 4), (89, 10), (90, 0), "
     ]
    }
   ],
   "source": [
    "for i in range(91):\n",
    "    if 'c_'+ str(i) in coco_category_count:\n",
    "        print((i, coco_category_count['c_'+ str(i)]), end=', ')\n",
    "    else: \n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64e0e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.945212Z",
     "iopub.status.busy": "2022-08-25T03:10:55.944916Z",
     "iopub.status.idle": "2022-08-25T03:10:55.949605Z",
     "shell.execute_reply": "2022-08-25T03:10:55.948983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 916), (1, 39), (2, 156), (3, 41), (4, 63), (5, 46), (6, 62), (7, 65), (8, 48), (9, 64), (10, 36), (11, 0), (12, 19), (13, 6), (14, 91), (15, 78), (16, 57), (17, 63), (18, 50), (19, 36), (20, 42), (21, 57), (22, 24), (23, 65), (24, 84), (25, 0), (26, 68), (27, 51), (28, 0), (29, 0), (30, 97), (31, 53), (32, 21), (33, 25), (34, 79), (35, 43), (36, 57), (37, 30), (38, 43), (39, 55), (40, 38), (41, 82), (42, 46), (43, 104), (44, 0), (45, 36), (46, 129), (47, 40), (48, 55), (49, 52), (50, 118), (51, 42), (52, 46), (53, 28), (54, 48), (55, 41), (56, 34), (57, 17), (58, 37), (59, 27), (60, 26), (61, 177), (62, 67), (63, 71), (64, 49), (65, 0), (66, 175), (67, 0), (68, 0), (69, 37), (70, 0), (71, 63), (72, 55), (73, 40), (74, 42), (75, 38), (76, 70), (77, 22), (78, 46), (79, 4), (80, 87), (81, 38), (82, 0), (83, 87), (84, 94), (85, 64), (86, 13), (87, 22), (88, 4), (89, 10), (90, 0), "
     ]
    }
   ],
   "source": [
    "for i in range(91):\n",
    "    if 'c_'+ str(i) in coco_category_count:\n",
    "        print((i, coco_category_count['c_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10751a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.952631Z",
     "iopub.status.busy": "2022-08-25T03:10:55.952334Z",
     "iopub.status.idle": "2022-08-25T03:10:55.956987Z",
     "shell.execute_reply": "2022-08-25T03:10:55.956386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 973), (1, 42), (2, 168), (3, 47), (4, 69), (5, 52), (6, 71), (7, 74), (8, 51), (9, 70), (10, 39), (11, 0), (12, 22), (13, 9), (14, 97), (15, 81), (16, 63), (17, 66), (18, 53), (19, 39), (20, 45), (21, 66), (22, 27), (23, 65), (24, 87), (25, 0), (26, 71), (27, 51), (28, 0), (29, 0), (30, 100), (31, 53), (32, 21), (33, 28), (34, 82), (35, 43), (36, 57), (37, 36), (38, 46), (39, 58), (40, 38), (41, 88), (42, 46), (43, 119), (44, 0), (45, 45), (46, 138), (47, 46), (48, 64), (49, 61), (50, 127), (51, 42), (52, 46), (53, 37), (54, 57), (55, 41), (56, 34), (57, 20), (58, 40), (59, 33), (60, 26), (61, 183), (62, 67), (63, 74), (64, 49), (65, 0), (66, 193), (67, 0), (68, 0), (69, 40), (70, 0), (71, 63), (72, 58), (73, 43), (74, 42), (75, 38), (76, 70), (77, 22), (78, 46), (79, 4), (80, 93), (81, 38), (82, 0), (83, 90), (84, 100), (85, 67), (86, 13), (87, 22), (88, 4), (89, 10), (90, 0), "
     ]
    }
   ],
   "source": [
    "for i in range(91):\n",
    "    if 'c_'+ str(i) in coco_category_count_trials:\n",
    "        print((i, coco_category_count_trials['c_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c83573c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.960073Z",
     "iopub.status.busy": "2022-08-25T03:10:55.959746Z",
     "iopub.status.idle": "2022-08-25T03:10:55.964218Z",
     "shell.execute_reply": "2022-08-25T03:10:55.963615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 536), (1, 400), (2, 195), (3, 527), (4, 228), (5, 396), (6, 291), (7, 250), (8, 390), (9, 178), (10, 120), (11, 265), "
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    if 's_'+ str(i) in coco_super_count:\n",
    "        print((i, coco_super_count['s_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f40a1072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.967102Z",
     "iopub.status.busy": "2022-08-25T03:10:55.966820Z",
     "iopub.status.idle": "2022-08-25T03:10:55.970871Z",
     "shell.execute_reply": "2022-08-25T03:10:55.970286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 560), (1, 439), (2, 210), (3, 563), (4, 234), (5, 417), (6, 321), (7, 274), (8, 414), (9, 181), (10, 126), (11, 277), "
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    if 's_'+ str(i) in coco_super_count_trials:\n",
    "        print((i, coco_super_count_trials['s_'+ str(i)]), end=', ')\n",
    "    else:\n",
    "        print((i, 0), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cffd2b12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:10:55.974204Z",
     "iopub.status.busy": "2022-08-25T03:10:55.973894Z",
     "iopub.status.idle": "2022-08-25T03:37:30.891812Z",
     "shell.execute_reply": "2022-08-25T03:37:30.890420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 20:10:57.040963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-24 20:10:57.107076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-08-24 20:10:57.112122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 20:10:57.121910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-24 20:10:57.128274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-24 20:10:57.132148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-24 20:10:57.139904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-24 20:10:57.146332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-24 20:10:57.157447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-24 20:10:57.158736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-08-24 20:10:57.159313: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-08-24 20:10:57.171247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz\n",
      "2022-08-24 20:10:57.171599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55556640af40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-24 20:10:57.171635: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-08-24 20:10:57.296585: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55556641ef90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-24 20:10:57.296629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2022-08-24 20:10:57.297353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-08-24 20:10:57.297422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 20:10:57.297444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-24 20:10:57.297464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-24 20:10:57.297483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-24 20:10:57.297502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-24 20:10:57.297522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-24 20:10:57.297541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-24 20:10:57.298290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-08-24 20:10:57.298345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 20:10:57.299902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-24 20:10:57.299919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-08-24 20:10:57.299933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-08-24 20:10:57.300832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14902 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 20:11:23.382809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-24 20:11:23.590948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for roi_name in roi_names:\n",
    "    file_name = roi_dir+sub + '_GLMbetas-TYPED-FITHRF-GLMDENOISE-RR_allses_' + roi_name + '.npy'\n",
    "    roi = np.load(file_name)\n",
    "    pad = np.zeros((roi.shape[0],522-roi.shape[1]), dtype=np.float32)\n",
    "    roi = np.concatenate((roi, pad), axis=1) \n",
    "    if roi_name == roi_names[0]:\n",
    "        rois = roi\n",
    "    else:\n",
    "        rois = np.concatenate((rois, roi), axis=1)\n",
    "'''    \n",
    "# nasnet = tf.keras.applications.nasnet.NASNetLarge()\n",
    "# tf.keras.models.save_model(nasnet, '/scratch/st-ipor-1/mkhademi/image_data/NASNetlarge.h5')\n",
    "nasnet = tf.keras.models.load_model('/scratch/st-ipor-1/mkhademi/image_data/NASNetlarge.h5')\n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_coco.tfrecords'\n",
    "writer_coco = tf.io.TFRecordWriter(filename)\n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_common.tfrecords'\n",
    "writer_common = tf.io.TFRecordWriter(filename) \n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_common_vehicle.tfrecords'\n",
    "writer_common_vehicle = tf.io.TFRecordWriter(filename)\n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_common_animal.tfrecords'\n",
    "writer_common_animal = tf.io.TFRecordWriter(filename) \n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_common_food.tfrecords'\n",
    "writer_common_food = tf.io.TFRecordWriter(filename)\n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_common_tool.tfrecords'\n",
    "writer_common_tool = tf.io.TFRecordWriter(filename)\n",
    "i = 0\n",
    "for ses in seses:\n",
    "    filename = output_dir + 'image_data/' + sub + 'bold5000_common_' + ses + '.tfrecords'\n",
    "    writer_common_ses = tf.io.TFRecordWriter(filename)\n",
    "    #img4d = nib.load(data_dir + sub + '_GLMbetas-TYPED-FITHRF-GLMDENOISE-RR_' + ses + '.nii.gz')\n",
    "    img4d = nib.load(warp_dir + sub + '_GLMbetas-TYPED-FITHRF-GLMDENOISE-RR_' + ses + '-n' + '.nii.gz')\n",
    "    # avg = mean_img(img4d)\n",
    "    # nib.save(avg, output_dir + 'image_data/' + sub + '-' + ses + '-avg.nii.gz')\n",
    "    selected_volumes = nilearn.image.index_img(img4d, slice(0, img4d.shape[3]))\n",
    "    for x in nilearn.image.iter_img(selected_volumes):\n",
    "        '''\n",
    "        if sub != subjs[0]:\n",
    "            #x = nilearn.image.resample_img(x, target_shape=(71, 89, 72), target_affine=x.affine)\n",
    "            x = nilearn.image.resample_img(x, target_shape=(91, 109, 91), target_affine=x.affine)\n",
    "        '''\n",
    "        # x_roi = np.copy(rois[i])\n",
    "        x_resample = nilearn.image.resample_img(x, target_shape=(79, 95, 69), target_affine=x.affine)\n",
    "        x_resample = np.array(x_resample.dataobj)\n",
    "        x_resample = np.nan_to_num(x_resample, nan = 0.0)\n",
    "        for roi_name in roi_names:\n",
    "            roi = nib.load(roi_dir + roi_name + '.img')\n",
    "            roi = np.array(roi.dataobj)\n",
    "            roi = x_resample[np.nonzero(roi)]\n",
    "            pad = np.zeros((5085-roi.shape[0]), dtype=np.float32)\n",
    "            roi = np.concatenate((roi, pad), axis=0) \n",
    "            if roi_name == roi_names[0]:\n",
    "                rois = roi\n",
    "            else:\n",
    "                rois = np.concatenate((rois, roi), axis=0)\n",
    "        x_roi = np.copy(rois)\n",
    "        x = np.array(x.dataobj)\n",
    "        x = np.nan_to_num(x, nan = 0.0)\n",
    "        x = np.reshape(x, (-1))\n",
    "        imgname = imgnames[i]\n",
    "        i += 1\n",
    "        common = False\n",
    "        coco_label = np.zeros(90, dtype=np.int32)\n",
    "        imagenet_label = np.zeros(1000, dtype=np.int32) \n",
    "        if imgname[0] == 'C':\n",
    "            img_path =  data_dir + 'image_data/MSCOCO/images/train2014/' + imgname \n",
    "            coco_label = img_dict[imgname]\n",
    "            super_label = img_dict_super[imgname]\n",
    "            tool_label = 0\n",
    "            for idx in tool:\n",
    "                if coco_label[idx] == 1:\n",
    "                    tool_label = 1\n",
    "                    break       \n",
    "            common_label = np.concatenate((coco_label, super_label, np.array([tool_label], dtype=np.int32)), axis=0)\n",
    "            common = True  \n",
    "        if  imgname[0]  == 'n' and (imgname[1] == '0' or imgname[1] == '1') and imgname in img_dict:\n",
    "            img_path = data_dir + '/image_data/ILSVRC/Data/CLS-LOC/train/' + imgname[:9] + '/' + imgname\n",
    "            imagenet_label = img_dict[imgname]\n",
    "            category_id = imagenet_categories.index(imgname[:9])\n",
    "            if category_id in cat_conv_rev:\n",
    "                coco_label[cat_conv_rev[category_id]] = 1\n",
    "                common = True\n",
    "            if extra_annotations[imgname] == 'face':\n",
    "                common = True\n",
    "                coco_label[0] = 1\n",
    "            if extra_annotations[imgname] == 'person_noface':\n",
    "                common = True\n",
    "                coco_label[0] = 1\n",
    "            super_label = img_dict_super[imgname]\n",
    "            tool_label = 0\n",
    "            for idx in tool:\n",
    "                if coco_label[idx] == 1:\n",
    "                    tool_label = 1\n",
    "                    break \n",
    "            common_label = np.concatenate((coco_label, super_label, np.array([tool_label], dtype=np.int32)), axis=0)\n",
    "        if common:\n",
    "            image = tf.keras.preprocessing.image.load_img(img_path, target_size=(331, 331))\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "            image = tf.keras.applications.nasnet.preprocess_input(image)  \n",
    "            yhat = nasnet.predict(image)\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'x': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "                'roi': tf.train.Feature(float_list=tf.train.FloatList(value=x_roi)),\n",
    "                'yhat': tf.train.Feature(float_list=tf.train.FloatList(value=yhat[0])),\n",
    "                'y_coco': tf.train.Feature(int64_list=tf.train.Int64List(value=coco_label)),\n",
    "                'y_imagenet': tf.train.Feature(int64_list=tf.train.Int64List(value=imagenet_label)),\n",
    "                'y_super': tf.train.Feature(int64_list=tf.train.Int64List(value=super_label)),\n",
    "                'y_common': tf.train.Feature(int64_list=tf.train.Int64List(value=common_label))\n",
    "                }))\n",
    "            writer_common.write(example.SerializeToString())\n",
    "            writer_common_ses.write(example.SerializeToString())\n",
    "            if imgname[0] == 'C':\n",
    "                writer_coco.write(example.SerializeToString())\n",
    "            if common_label[2] or common_label[4] or common_label[6] or common_label[7]:\n",
    "                writer_common_vehicle.write(example.SerializeToString())\n",
    "            if common_label[15] or common_label[16] or common_label[17] or common_label[24]:\n",
    "                writer_common_animal.write(example.SerializeToString())\n",
    "            if common_label[51] or common_label[52] or common_label[54] or common_label[55]:\n",
    "                writer_common_food.write(example.SerializeToString())\n",
    "            if common_label[30] or common_label[48] or common_label[49] or common_label[76]:\n",
    "                writer_common_tool.write(example.SerializeToString())\n",
    "    writer_common_ses.close()\n",
    "\n",
    "writer_coco.close()\n",
    "writer_common.close()\n",
    "writer_common_vehicle.close()\n",
    "writer_common_animal.close()\n",
    "writer_common_food.close()\n",
    "writer_common_tool.close()\n",
    "# -4218170.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09c18dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T03:37:30.896264Z",
     "iopub.status.busy": "2022-08-25T03:37:30.895881Z",
     "iopub.status.idle": "2022-08-25T03:37:30.915975Z",
     "shell.execute_reply": "2022-08-25T03:37:30.915329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/pbs.4029679.pbsha.ib.sockeye/ipykernel_235327/2148738918.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 20:37:30.902702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-08-24 20:37:30.902878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 20:37:30.902909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-24 20:37:30.902938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-24 20:37:30.902966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-24 20:37:30.902991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-24 20:37:30.903016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-24 20:37:30.903042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-24 20:37:30.903796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-08-24 20:37:30.903858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-24 20:37:30.903870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-08-24 20:37:30.903879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-08-24 20:37:30.904634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/device:GPU:0 with 14902 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfilename = output_dir + 'image_data/' + sub + 'bold5000_recons.tfrecords'\\nwriter_recons = tf.io.TFRecordWriter(filename)\\nimg_rows, img_cols, channels = 56, 56, 3\\ni=0\\nimagenet_str = '/image_data/ILSVRC/Data/CLS-LOC/train/'\\nfor ses in seses:\\n    img4d = nib.load(data_dir + sub + '_GLMbetas-TYPED-FITHRF-GLMDENOISE-RR_' + ses + '.nii.gz')\\n    selected_volumes = nilearn.image.index_img(img4d, slice(0, img4d.shape[3]))\\n    for x in nilearn.image.iter_img(selected_volumes):\\n        if sub != subjs[0]:\\n            x = nilearn.image.resample_img(x, target_shape=(71, 89, 72), target_affine=x.affine)\\n        x = np.array(x.dataobj)\\n        x = np.nan_to_num(x, nan = 0.0)\\n        x = np.reshape(x, (-1))\\n        imgname = imgnames[i]\\n        i += 1\\n        if imgname[0] == 'C':\\n            img_path =  data_dir + 'image_data/MSCOCO/images/train2014/' + imgname \\n        if  imgname[0]  == 'n' and (imgname[1] == '0' or imgname[1] == '1'):\\n            img_path = data_dir + imagenet_str + imgname[:9] + '/' + imgname\\n        image = tf.keras.preprocessing.image.load_img(img_path, target_size=(331, 331))\\n        image = tf.keras.preprocessing.image.img_to_array(image)\\n        image = tf.reshape(tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))),\\n                              tf.float32) / 127.5 - 1, (1, img_rows, img_cols, channels))\\n        image = np.reshape(image,(-1))\\n        example = tf.train.Example(features=tf.train.Features(feature={\\n            'x': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\\n            'image': tf.train.Feature(float_list=tf.train.FloatList(value=image))}))\\n        writer_recons.write(example.SerializeToString())\\nwriter_recons.close()\\nprint(i)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print('done.')\n",
    "'''\n",
    "filename = output_dir + 'image_data/' + sub + 'bold5000_recons.tfrecords'\n",
    "writer_recons = tf.io.TFRecordWriter(filename)\n",
    "img_rows, img_cols, channels = 56, 56, 3\n",
    "i=0\n",
    "imagenet_str = '/image_data/ILSVRC/Data/CLS-LOC/train/'\n",
    "for ses in seses:\n",
    "    img4d = nib.load(data_dir + sub + '_GLMbetas-TYPED-FITHRF-GLMDENOISE-RR_' + ses + '.nii.gz')\n",
    "    selected_volumes = nilearn.image.index_img(img4d, slice(0, img4d.shape[3]))\n",
    "    for x in nilearn.image.iter_img(selected_volumes):\n",
    "        if sub != subjs[0]:\n",
    "            x = nilearn.image.resample_img(x, target_shape=(71, 89, 72), target_affine=x.affine)\n",
    "        x = np.array(x.dataobj)\n",
    "        x = np.nan_to_num(x, nan = 0.0)\n",
    "        x = np.reshape(x, (-1))\n",
    "        imgname = imgnames[i]\n",
    "        i += 1\n",
    "        if imgname[0] == 'C':\n",
    "            img_path =  data_dir + 'image_data/MSCOCO/images/train2014/' + imgname \n",
    "        if  imgname[0]  == 'n' and (imgname[1] == '0' or imgname[1] == '1'):\n",
    "            img_path = data_dir + imagenet_str + imgname[:9] + '/' + imgname\n",
    "        image = tf.keras.preprocessing.image.load_img(img_path, target_size=(331, 331))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image = tf.reshape(tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))),\n",
    "                              tf.float32) / 127.5 - 1, (1, img_rows, img_cols, channels))\n",
    "        image = np.reshape(image,(-1))\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'x': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "            'image': tf.train.Feature(float_list=tf.train.FloatList(value=image))}))\n",
    "        writer_recons.write(example.SerializeToString())\n",
    "writer_recons.close()\n",
    "print(i)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
